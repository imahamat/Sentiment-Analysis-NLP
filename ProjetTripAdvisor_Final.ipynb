{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetTripAdvisor_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0Bsea9HMHR5X"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-essa/Sentiment-Analysis-and-Satisfaction-Prediction/blob/master/ProjetTripAdvisor_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RU96zjHKc0",
        "colab_type": "text"
      },
      "source": [
        "# Projet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GUy0-jxDsmN",
        "colab_type": "code",
        "outputId": "f3af2038-5382-4dd3-c4f7-1f77da4f897f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMxmpyJDyPm",
        "colab_type": "code",
        "outputId": "d61f90ce-ab63-4241-f40b-6eaddd1e6688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import io\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.preprocessing.text\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import multilabel_confusion_matrix as mcm\n",
        "import tensorflow_hub as hub\n",
        "tf.keras.backend.clear_session()\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "pd.options.display.max_colwidth = 1000\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMZ5-6pjDz9J",
        "colab_type": "code",
        "outputId": "7b5ef206-c98a-446f-bf66-faed3a9b737f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4aDDiWiD5ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bsea9HMHR5X",
        "colab_type": "text"
      },
      "source": [
        "# Read CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWC424JhD-yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Total_data_for_tokenizer=pd.read_csv('/content/gdrive/My Drive/Data/Total_data_for_tokenizer.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QenSQ2ccHV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_TripAdvisor=pd.read_csv('/content/gdrive/My Drive/Data/training_set_TripAdvisor.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LE3idEjcHTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_TripAdvisor=pd.read_csv('/content/gdrive/My Drive/Data/test_set_TripAdvisor.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9IEqjrDcHJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_IMDB=pd.read_csv('/content/gdrive/My Drive/Data/training_set_IMDB.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAfJyS7ZcG83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set_IMDB=pd.read_csv('/content/gdrive/My Drive/Data/test_set_IMDB.csv' , sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAfKBU-zEOyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del Total_data_for_tokenizer['Unnamed: 0']\n",
        "del training_set_TripAdvisor['Unnamed: 0']\n",
        "del test_set_TripAdvisor['Unnamed: 0']\n",
        "del training_set_IMDB['Unnamed: 0']\n",
        "del test_set_IMDB['Unnamed: 0']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiq0-ziWHUtS",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOz-69QqEQhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(dataframe):\n",
        "  msk = np.random.rand(len(dataframe)) < 0.8\n",
        "\n",
        "  train = dataframe[msk]\n",
        "\n",
        "  test = dataframe[~msk]\n",
        "  #print(train_file_path.head)\n",
        "  all_data = np.array(dataframe.values.tolist())\n",
        "  training_set = np.array(train.values.tolist())\n",
        "  test_set=np.array(test.values.tolist())\n",
        "  print(\"Dataset Length: \",len(training_set)+ len(test_set))\n",
        "  return all_data, training_set, test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xmJa7elEaf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer(dataset):\n",
        "  tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token='UNK')\n",
        "  # fit the tokenizer on the documents\n",
        "  tokenizer.fit_on_texts(dataset[:,1])\n",
        "  # summarize what was learned\n",
        "  print(\"Word counter: \",tokenizer.word_counts)\n",
        "  print(\"Number of sentences: \",tokenizer.document_count)\n",
        "  print(\"Word Index: \", tokenizer.word_index)\n",
        "  print(\"Word Docs: \",tokenizer.word_docs)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzgs633HEcT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocab_size(tokenizer):\n",
        "  voca_size=len(tokenizer.word_counts)+2   # 1 ?\n",
        "  return voca_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeuYm_kfEeHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxlen(data):\n",
        "  return max([len(x) for x in data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUuLrAo6Fvzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Total_data_for_tokenizer_np = np.array(Total_data_for_tokenizer.values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFBvle7NFyRr",
        "colab_type": "code",
        "outputId": "4cb70e08-8ce8-475c-f811-aa47293b99f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "tokenizer=create_tokenizer(Total_data_for_tokenizer_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvPDBdUrFCkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_sentences(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      input_sequences.append(token_list)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGIquk1ad4b_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_IMDB_np = np.array(training_set_IMDB.values.tolist())\n",
        "test_set_IMDB_np = np.array(test_set_IMDB.values.tolist())\n",
        "training_set_TripAdvisor_np = np.array(training_set_TripAdvisor.values.tolist())\n",
        "test_set_TripAdvisor_np = np.array(test_set_TripAdvisor.values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2cPPJGIRFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_training_set_IMDB = tokenize_sentences(training_set_IMDB_np)\n",
        "input_test_set_IMDB = tokenize_sentences(test_set_IMDB_np)\n",
        "input_training_set_TripAdvisor = tokenize_sentences(training_set_TripAdvisor_np)\n",
        "input_test_set_TripAdvisor = tokenize_sentences(test_set_TripAdvisor_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47Oa5LZHDyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences(input_sequences, max_sequence_len):\n",
        "  input_padded_sequences = np.array(pad_sequences(input_sequences,   \n",
        "                            maxlen=max_sequence_len, padding='pre'))\n",
        "  return input_padded_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVNusWKhH1n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences_post(input_sequences, max_sequence_len):\n",
        "  input_padded_sequences = np.array(pad_sequences(input_sequences,   \n",
        "                            maxlen=max_sequence_len, padding='post'))\n",
        "  return input_padded_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZoxfGSD7Bz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxlen(data1, data2 , data3 , data4):\n",
        "  max_len_data1 = max([len(x) for x in data1])\n",
        "  max_len_data2 = max([len(x) for x in data2])\n",
        "  max_len_data3 = max([len(x) for x in data3])\n",
        "  max_len_data4 = max([len(x) for x in data4])\n",
        "  return max(max_len_data1, max_len_data2 , max_len_data3 , max_len_data4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhSPMGUSIZdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = maxlen(input_training_set_IMDB, input_test_set_IMDB, input_training_set_TripAdvisor, input_test_set_TripAdvisor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH2-LjrHLseD",
        "colab_type": "text"
      },
      "source": [
        "#Embeddings pretraining (Next Word Prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO09_K6rhKmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sentences_forward(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set:\n",
        "      for i in range(1, len(line)):\n",
        "        if i < 99 :\n",
        "          n_gram_sequence = line[:i+1]\n",
        "        else :\n",
        "          n_gram_sequence = line[i-99:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECyx4rQDL7yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sentences_Backward(input_set):\n",
        "  input_sequences = []\n",
        "  for line in input_set[:,1]:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      for i in range(1, len(token_list)):\n",
        "        if i < 99 :\n",
        "          n_gram_sequence = token_list[:i+1]\n",
        "        else :\n",
        "          n_gram_sequence = token_list[i-99:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "  return input_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3hhoLTQL7d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices_embaddings(input_sequences):\n",
        "  predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "  #label = tf.keras.utils.to_categorical(label, num_classes=voc_size)\n",
        "  return predictors, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaD5DgDdL7X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_preprocessed_dataset(predictors, labels):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((predictors, labels))\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j957uTnYL7SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_k_categorical_accuracy1(y_true, y_pred, k=10):\n",
        "    return K.mean(K.in_top_k(K.cast(y_pred,dtype='float32'),K.argmax(y_true, axis=-1), k), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z77__hlvmSAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_WE_1=split_sentences_forward(input_training_set_IMDB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uo-sgQVL7ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_WE_2=split_sentences_forward(input_training_set_TripAdvisor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl1SrkOlL7EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test_WE_1=split_sentences_forward(input_test_set_IMDB[5000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Kq5ZeXNxPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test_WE_2=split_sentences_forward(input_test_set_TripAdvisor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToeSIb11N_hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_WE_sequences_1 = pad_sentences(input_train_WE_1, 100)\n",
        "input_train_WE_sequences_2 = pad_sentences(input_train_WE_2, 100)\n",
        "input_test_WE_sequences_1 = pad_sentences(input_test_WE_1, 100)\n",
        "input_test_WE_sequences_2 = pad_sentences(input_test_WE_2, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dizSto_OA7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors_WE, training_label_WE=create_dataset_slices_embaddings(input_train_WE_sequences_1)\n",
        "test_predictors_WE, test_label_WE= create_dataset_slices_embaddings(input_test_WE_sequences_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzHWW7OTOAz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors_WE_2, training_label_WE_2=create_dataset_slices_embaddings(input_train_WE_sequences_2)\n",
        "test_predictors_WE_2, test_label_WE_2= create_dataset_slices_embaddings(input_test_WE_sequences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okRfBEGkOArD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_size = vocab_size(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42UyQQ-OAkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer = tf.keras.layers.Embedding(voc_size, 64)\n",
        "LstmLayer = tf.keras.layers.LSTM(150)\n",
        "DenseLayerEmbedding = tf.keras.layers.Dense(64, activation='relu')\n",
        "DropLayerEmbedding = tf.keras.layers.Dropout(0.1)\n",
        "DenseLayerOutputEmbedding = tf.keras.layers.Dense(voc_size, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le1jonZJOAdM",
        "colab_type": "code",
        "outputId": "ea81246e-f2c7-498c-e6d8-b6ee298ffd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(EmbeddingLayer)\n",
        "model.add(LstmLayer)\n",
        "model.add(DenseLayerEmbedding)\n",
        "model.add(DropLayerEmbedding)\n",
        "model.add(DenseLayerOutputEmbedding)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          5120512   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 150)               129000    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                9664      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 80008)             5200520   \n",
            "=================================================================\n",
            "Total params: 10,459,696\n",
            "Trainable params: 10,459,696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letBgMTdOAVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3zGjAZyPTNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"training_Embadding/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKQJD5J3PURJ",
        "colab_type": "code",
        "outputId": "f9f6106f-b2d8-4997-a478-c2ed5b29076a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "history = model.fit(training_predictors_WE, \n",
        "                    training_label_WE,\n",
        "                    epochs=2,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_WE, test_label_WE),\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3616784 samples, validate on 2831359 samples\n",
            "Epoch 1/2\n",
            "3616700/3616784 [============================>.] - ETA: 0s - loss: 7.6951 - accuracy: 0.0596\n",
            "Epoch 00001: saving model to training_Embadding/cp-0001.ckpt\n",
            "3616784/3616784 [==============================] - 2552s 706us/sample - loss: 7.6951 - accuracy: 0.0596 - val_loss: 7.5867 - val_accuracy: 0.0709\n",
            "Epoch 2/2\n",
            "2262000/3616784 [=================>............] - ETA: 12:57 - loss: 7.4362 - accuracy: 0.0723Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLrNPWztPYRG",
        "colab_type": "code",
        "outputId": "f34c184c-a19a-4285-d749-244775136241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "history = model.fit(training_predictors_WE_2, \n",
        "                    training_label_WE_2,\n",
        "                    epochs=2,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_WE_2, test_label_WE_2),\n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 947983 samples, validate on 237895 samples\n",
            "Epoch 1/2\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 5.7982 - accuracy: 0.1446\n",
            "Epoch 00001: saving model to training_Embadding/cp-0001.ckpt\n",
            "947983/947983 [==============================] - 547s 577us/sample - loss: 5.7982 - accuracy: 0.1446 - val_loss: 5.1032 - val_accuracy: 0.1927\n",
            "Epoch 2/2\n",
            "947900/947983 [============================>.] - ETA: 0s - loss: 4.9881 - accuracy: 0.1962\n",
            "Epoch 00002: saving model to training_Embadding/cp-0002.ckpt\n",
            "947983/947983 [==============================] - 528s 557us/sample - loss: 4.9881 - accuracy: 0.1962 - val_loss: 4.7930 - val_accuracy: 0.2161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AbTOCWHoBzG",
        "colab_type": "text"
      },
      "source": [
        "#Dataset slices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z4DMzBePkFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDb5mtweJn4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_train_CL_sequences_1 = pad_sentences_post(input_training_set_IMDB, max_len)\n",
        "input_train_CL_sequences_2 = pad_sentences_post(input_training_set_TripAdvisor, max_len)\n",
        "input_test_CL_sequences_1 = pad_sentences_post(input_test_set_IMDB, max_len)\n",
        "input_test_CL_sequences_2 = pad_sentences_post(input_test_set_TripAdvisor, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHTJtoZX6kiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_slices_sentence_Regre(input_sequences, targets):\n",
        "  predictors= tf.constant(input_sequences)\n",
        "  targets=targets.astype(int)\n",
        "  return predictors, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUk2Kxu_-_JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_predictors, training_label=create_dataset_slices_sentence_Regre(input_train_CL_sequences_2,training_set_TripAdvisor_np[:,0])\n",
        "test_predictors, test_label=create_dataset_slices_sentence_Regre(input_test_CL_sequences_2,test_set_TripAdvisor_np[:,0])\n",
        "training_predictors_tfds, training_label_tfds=create_dataset_slices_sentence_Regre(input_train_CL_sequences_1,training_set_IMDB_np[:,0])\n",
        "test_predictors_tfds, test_label_tfds=create_dataset_slices_sentence_Regre(input_test_CL_sequences_1,test_set_IMDB_np[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUsPBdq0AIA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHE3tINdgJZk",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmjRPMxwF-YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BidirectionalLayer1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))\n",
        "BidirectionalLayer2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))\n",
        "GlobalMaxPool1DLayer = tf.keras.layers.GlobalMaxPool1D()\n",
        "DenseLayer1 = tf.keras.layers.Dense(40, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) , activation='relu')\n",
        "DropLayer = tf.keras.layers.Dropout(0.1)\n",
        "DenseLayerOutputRE = tf.keras.layers.Dense(1, activation=tf.keras.activations.linear)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR-1L84Ixe6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ4HZqaGAIe",
        "colab_type": "code",
        "outputId": "2f7289f6-3f4f-4cf6-98f7-af4819b3dd47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "modelBin = tf.keras.Sequential()\n",
        "modelBin.add(EmbeddingLayer)\n",
        "modelBin.add(BidirectionalLayer1)\n",
        "modelBin.add(BidirectionalLayer2)\n",
        "modelBin.add(GlobalMaxPool1DLayer)\n",
        "modelBin.add(DenseLayer1)\n",
        "modelBin.add(DropLayer)\n",
        "modelBin.add(DenseLayerOutputRE)\n",
        "modelBin.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          5120512   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 128)         66048     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 128)         98816     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 40)                5160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 40)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 41        \n",
            "=================================================================\n",
            "Total params: 5,290,577\n",
            "Trainable params: 170,065\n",
            "Non-trainable params: 5,120,512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03WxorAGbGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelBin.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qybjUaHDd-Kd",
        "colab_type": "code",
        "outputId": "4969560d-36f8-49d6-a7a5-50651e3e4a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "history = modelBin.fit(training_predictors_tfds, \n",
        "                    training_label_tfds,\n",
        "                    epochs=3,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_tfds, test_label_tfds),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/3\n",
            "25000/25000 [==============================] - 158s 6ms/sample - loss: 0.3988 - mse: 0.1875 - mae: 0.3710 - val_loss: 0.2184 - val_mse: 0.1716 - val_mae: 0.3166\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 152s 6ms/sample - loss: 0.1737 - mse: 0.1491 - mae: 0.3064 - val_loss: 0.1576 - val_mse: 0.1442 - val_mae: 0.3057\n",
            "Epoch 3/3\n",
            "24300/25000 [============================>.] - ETA: 2s - loss: 0.1416 - mse: 0.1319 - mae: 0.2760"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7L6m8imUZF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer.trainable = True "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8tbz_0eUaI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelBin.compile(loss='mean_squared_error', \n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDBQTA1DPPPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = modelBin.fit(training_predictors_tfds, \n",
        "                    training_label_tfds,\n",
        "                    epochs=2,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors_tfds, test_label_tfds),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtibcmeZGhbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = tf.keras.Sequential()\n",
        "model1.add(EmbeddingLayer)\n",
        "model1.add(BidirectionalLayer1)\n",
        "model1.add(BidirectionalLayer2)\n",
        "model1.add(GlobalMaxPool1DLayer)\n",
        "model1.add(DenseLayer1)\n",
        "model1.add(DropLayer)\n",
        "model1.add(DenseLayerOutputRE)\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a7MmhXYQT3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer.trainable = False\n",
        "BidirectionalLayer1.trainable = False\n",
        "BidirectionalLayer2.trainable = False\n",
        "GlobalMaxPool1DLayer.trainable = False\n",
        "DenseLayer1.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tt-sgMnGj60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chEjfQ_ILDUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model1.fit(training_predictors, \n",
        "                    training_label,\n",
        "                    epochs=5,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors, test_label),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp-QqmElQiZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DenseLayer1.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V26QjvEQj4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKZdumuiQlp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model1.fit(training_predictors, \n",
        "                    training_label,\n",
        "                    epochs=4,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors, test_label),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ORlzgH4lCN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EmbeddingLayer.trainable = True\n",
        "BidirectionalLayer1.trainable = True\n",
        "BidirectionalLayer2.trainable = True\n",
        "GlobalMaxPool1DLayer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaNOz-CllDIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='mean_squared_error',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['mse','mae','accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTfh2gHFlEtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model1.fit(training_predictors, \n",
        "                    training_label,\n",
        "                    epochs=4,\n",
        "                    batch_size=100,\n",
        "                    validation_data=(test_predictors, test_label),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr8WjtWNgYtQ",
        "colab_type": "text"
      },
      "source": [
        "#From saved weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs8j6nEQgeLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''EmbeddingLayer = tf.keras.layers.Embedding(80008, 64)\n",
        "BidirectionalLayer1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))\n",
        "BidirectionalLayer2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True))\n",
        "GlobalMaxPool1DLayer = tf.keras.layers.GlobalMaxPool1D()\n",
        "DenseLayer1 = tf.keras.layers.Dense(40, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) , activation='relu')\n",
        "DropLayer = tf.keras.layers.Dropout(0.1)\n",
        "DenseLayerOutputRE = tf.keras.layers.Dense(1, activation=tf.keras.activations.linear)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpbl5offgsj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''model1 = tf.keras.Sequential()\n",
        "model1.add(EmbeddingLayer)\n",
        "model1.add(BidirectionalLayer1)\n",
        "model1.add(BidirectionalLayer2)\n",
        "model1.add(GlobalMaxPool1DLayer)\n",
        "model1.add(DenseLayer1)\n",
        "model1.add(DropLayer)\n",
        "model1.add(DenseLayerOutputRE)\n",
        "\n",
        "model1.summary()'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLWrk5xfgvsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''model1.load_weights('/content/gdrive/My Drive/Chekpoints/model_checkpoint')'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO2mKXRdge03",
        "colab_type": "text"
      },
      "source": [
        "#Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqfiKMwKq-H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaCQXgwWpfrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "  \n",
        "def clean_set(set_len):\n",
        "  stop_words = list(stopwords.words('english'))\n",
        "  stop_words.remove(\"not\")\n",
        "  stop_words.remove(\"no\")\n",
        "  stop_words.remove(\"isn't\")\n",
        "  stop_words.remove(\"hasn't\")\n",
        "  stop_words.remove(\"wasn't\")\n",
        "  stop_words.remove(\"didn't\")\n",
        "  stop_words.remove(\"haven't\")\n",
        "  stop_words.remove(\"don't\")\n",
        "  stop_words.remove(\"doesn't\")\n",
        "  stop_words.remove(\"weren't\")\n",
        "  stop_words.remove(\"shouldn't\")\n",
        "  lemmatizer = WordNetLemmatizer() \n",
        "  for elem in set_len:\n",
        "    word_tokens = word_tokenize(elem[1]) \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(lemmatizer.lemmatize(w)) \n",
        "    elem[1]=' '.join(filtered_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDe-uwk8oxqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['reviews.rating','reviews.text']\n",
        "eval_data = pd.read_csv('http://christophe-rodrigues.fr/eval_reviews.csv', usecols=column_names, sep=\";\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAH9mDsBHVK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_data = np.array(eval_data.values.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYGkw0T5pr4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_set(eval_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cx2778iHQx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_data_Text = tokenize_sentences(eval_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gnBtXY0HwJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_eval = pad_sentences_post(eval_data_Text, max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVHty4wtILTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_predictors, eval_label =create_dataset_slices_sentence_Regre(input_eval,eval_data[:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aH4dU4kIxn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model1.predict(eval_predictors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuReGcE1I6Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse = mean_squared_error(prediction, eval_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFHrxe_IJ62I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9I9W_k2d9KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}